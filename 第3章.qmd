---
title: "第3章"
format: 
  html:
    theme: journal
    highlight-style: pygments
number-sections: true
toc: true
toc-depth: 3
toc-location: left
code-fold: show #code-fold:showでコードの折り畳みが可能
date: "最終更新: `r Sys.Date()`"
---

```{r setup, include=FALSE}
rm(list = ls()) #knitで正しく結果を得るため最初に全て消去
knitr::opts_chunk$set(cache = FALSE, echo = TRUE, fig.align = "center", warning = FALSE)
library(ggplot2)
library(tictoc)
library(CausalInferenceTextbook)
library(clubSandwich)
library(foreach)
library(magrittr)
library(kableExtra)
library(modelsummary)
color_main <- scales::viridis_pal(option = "C")(1)
```

```{r include=FALSE}
# CRANから削除されているため、GitHubからインストール
# Sys.setenv(GITHUB_PAT = "...")
# devtools::install_github("s3alfisc/fwildclusterboot@v.0.12")
library(fwildclusterboot)
```

# クラスターブートストラップ

参照：[因果推論の計量経済学（川口、澤田）：第3章　推測・検定の諸問題](https://github.com/keisemi/EconometriciansGuide_CausalInference/blob/main/main/Inference_wild_cluster_bootstrap.html)

## クラスターの数が少なくないケース

### データの生成

```{r}
# seedの固定
set.seed(1)
dqrng::dqset.seed(1)

# 定数の設定
N <- 50      #観測数
N_C <- 100　 #クラスター数1　
N_M <- 500   #クラスター数2 5000→500に減らして対応
N_B <- 999   #クラスター数3 9999→999に減らして対応

# データの生成
data_large_cluster <- 
  return_dgp_cluster(
    N = N,
    N_C = N_C
  )
```

### 統計量の計算

参照サイトではlmサマリのt値をそのまま使用しているが、不均一分散頑強標準誤差による推計のため、sandwich::vcovHCで分散を出し、不均一分散頑強標準誤差によるt値を手動で算出。

```{r}
lm_fit <- 
  lm(Y ~ X, data = data_large_cluster)

t_HC <-
  summary(lm_fit)$coefficients[2,1] / 
  sqrt(sandwich::vcovHC(lm_fit, type = "HC"))[2, 2]

cat("Heteroskedasticity-robust t-statistics",
    t_HC,
    "\n")
```

clubSandwichパッケージでクラスター頑健分散推定を行う。 HC,HACに対応した分散推定を行うsandwichパッケージとは異なる。

```{r}
vc_cr0 <- 
  clubSandwich::vcovCR(
    lm_fit,
    cluster = data_large_cluster$C,
    type = "CR0" #補正なし
  )

vc_cr3 <- 
  clubSandwich::vcovCR(
    lm_fit,
    cluster = data_large_cluster$C,
    type = "CR3" #ジャックナイフ分散推定
  )

cat(
  "Cluster-robust t-statistics, CR0",
  clubSandwich::coef_test(
    lm_fit,
    vc_cr0,
    coefs = "X"
  )$tstat,
  "\n"
)
```

```{r}
cat(
  "Cluster-robust t-statistics, CR3",
  clubSandwich::coef_test(
    lm_fit,
    vc_cr3,
    coefs = "X"
  )$tstat,
  "\n"
)
```

ワイルドブートストラップによる推計

```{r cache=TRUE}
p_val_w <- 
  fwildclusterboot::boottest(
    object = lm_fit,
    clustid = "C",
    param = "X",
    B = N_B,
    type = "webb"
  )$p_val
cat("Wild cluster-bootstrap p-value", p_val_w, "\n")
```

### シミュレーション比較

```{r cache=TRUE}
t_w <- rep(NA, N_M)
t_cr0 <- rep(NA, N_M)
t_cr3 <- rep(NA, N_M)
p_cr_w <- rep(NA, N_M)

for(i in 1:N_M) {
  data_large_cluster <- 
    return_dgp_cluster(
      N = N,
      N_C = N_C
    )
  
  lm_fit <- 
    lm(Y ~ X, data = data_large_cluster)
  
  t_w[i] <- summary(lm_fit)$coefficients[2,3]
  
  vc_cr0 <- 
    clubSandwich::vcovCR(
      lm_fit,
      cluster = data_large_cluster$C,
      type = "CR0"
    )
  
  vc_cr3 <- 
    clubSandwich::vcovCR(
      lm_fit,
      cluster = data_large_cluster$C,
      type = "CR3"
    )
  
  t_cr0[i] <- 
    clubSandwich::coef_test(
      lm_fit,
      vc_cr0,
      coefs = "X"
    )$tstat
  
  t_cr3[i] <- 
    clubSandwich::coef_test(
      lm_fit,
      vc_cr3,
      coefs = "X"
    )$tstat
  
  invisible(
    capture.output(
      boot_lm <- 
        fwildclusterboot::boottest(
          object = lm_fit,
          clustid = "C",
          param = "X",
          B = N_B,
          type = "webb"
        )
    )
  )
  
  invisible(
    capture.output(
      p_cr_w[i] <- boot_lm$p_val
    )
  )
}
```

各分散推定における棄却確率

```{r}
result_large <- 
  tibble::tibble(
    specifications = c(
      "Heteroskedasticity-robust",
      "Cluster-robust CR0",
      "Cluster-robust CR3",
      "Wild Cluster Bootstrap"
    ),
    rejection_probability = c(
      mean(abs(t_w) >= 1.965, na.rm = TRUE),
      mean(abs(t_cr0) >= 1.965, na.rm = TRUE),
      mean(abs(t_cr3) >= 1.965, na.rm = TRUE),
      mean(p_cr_w < 0.05, na.rm = TRUE)
    )
  )
result_large |> 
  kableExtra::kbl() |> 
  kableExtra::kable_styling()
```

## クラスターの数が少ないケース

### データの生成

```{r}
# seedの固定
set.seed(1)
dqrng::dqset.seed(1)

# 定数の再設定
N <- 50
N_C <- 20
N_M <- 500
N_B <- 999
```

### シミュレーション比較

```{r}
t_w <- rep(NA, N_M)
t_cr0 <- rep(NA, N_M)
t_cr3 <- rep(NA, N_M)
p_cr_w <- rep(NA, N_M)

for(i in 1:N_M) {
  data_small_cluster <- 
    return_dgp_cluster(
      N = N,
      N_C = N_C
    )
  
  lm_fit <- 
    lm(Y ~ X, data = data_small_cluster)
  
  t_w[i] <- summary(lm_fit)$coefficients[2,3]
  
  vc_cr0 <- 
    clubSandwich::vcovCR(
      obj = lm_fit,
      cluster = data_small_cluster$C,
      type = "CR0"
    )
  
  vc_cr3 <- 
    clubSandwich::vcovCR(
      obj = lm_fit,
      cluster = data_small_cluster$C,
      type = "CR3"
    )
  
  t_cr0[i] <- 
    clubSandwich::coef_test(
      obj = lm_fit,
      vcov = vc_cr0,
      coefs = "X",
    )$tstat
  
  t_cr3[i] <- 
    clubSandwich::coef_test(
      obj = lm_fit,
      vcov = vc_cr3,
      coefs = "X"
    )$tstat
  
  invisible(
    capture.output(
      boot_lm <- 
        fwildclusterboot::boottest(
          object = lm_fit,
          clustid = "C",
          param = "X",
          B = N_B,
          type = "webb"
        )
    )
  )
  
  invisible(
    capture.output(
      p_cr_w[i] <- boot_lm$p_val
    )
  )
}

```

各分散推定における棄却確率

```{r}
result_small <- 
  tibble::tibble(
    specifications = c(
      "Heteroskedasticity-robust",
      "Cluster-robust CR0",
      "Cluster-robust CR3",
      "Wild Cluster Bootstrap"
    ),
    rejection_probability = c(
      mean(abs(t_w) >= 1.965, na.rm = TRUE),
      mean(abs(t_cr0) >= 1.965, na.rm = TRUE),
      mean(abs(t_cr3) >= 1.965, na.rm = TRUE),
      mean(p_cr_w < 0.05, na.rm = TRUE)
      )
  )
result_small |> 
  kableExtra::kbl() |> 
  kableExtra::kable_styling()
```

## クラスターの数が極端に少ないケース

### データの生成

```{r}
# seedの再固定
set.seed(1)
dqrng::dqset.seed(1)

# 定数の再設定
N <- 100
N_C <- 8
N_M <- 500
N_B <- 999
```

### シミュレーション比較

boottestのtypeをwebbに設定して実施

```{r}
t_w <- rep(NA, N_M)
t_cr0 <- rep(NA, N_M)
t_cr3 <- rep(NA, N_M)
p_cr_w <- rep(NA, N_M)

for(i in 1:N_M) {
  data_extremely_small_cluster <- 
    return_dgp_cluster(
      N = N,
      N_C = N_C
    )
  
  lm_fit <- 
    lm(Y ~ X, data = data_extremely_small_cluster)
  
  t_w[i] <- summary(lm_fit)$coefficients[2,3]
  
  vc_cr0 <- 
    clubSandwich::vcovCR(
      obj = lm_fit,
      cluster = data_extremely_small_cluster$C,
      type = "CR0"
    )
  
  vc_cr3 <- 
    clubSandwich::vcovCR(
      obj = lm_fit,
      cluster = data_extremely_small_cluster$C,
      type = "CR3"
    )
  
  t_cr0[i] <- 
    clubSandwich::coef_test(
      obj = lm_fit,
      vcov = vc_cr0,
      coefs = "X",
    )$tstat
  
  t_cr3[i] <- 
    clubSandwich::coef_test(
      obj = lm_fit,
      vcov = vc_cr3,
      coefs = "X"
    )$tstat
  
  invisible(
    capture.output(
      boot_lm <- 
        fwildclusterboot::boottest(
          object = lm_fit,
          clustid = "C",
          param = "X",
          B = N_B,
          type = "webb"
        )
    )
  )
  
  invisible(
    capture.output(
      p_cr_w[i] <- boot_lm$p_val
    )
  )
}
```

```{r}
result_extremely_small <- 
  tibble::tibble(
    specifications = c(
      "Heteroskedasticity-robust",
      "Cluster-robust CR0",
      "Cluster-robust CR3",
      "Wild Cluster Bootstrap"
    ),
    rejection_probability = c(
      mean(abs(t_w) >= 1.965, na.rm = TRUE),
      mean(abs(t_cr0) >= 1.965, na.rm = TRUE),
      mean(abs(t_cr3) >= 1.965, na.rm = TRUE),
      mean(p_cr_w < 0.05, na.rm = TRUE)
      )
  )
result_extremely_small |> 
  kableExtra::kbl() |> 
  kableExtra::kable_styling()
```

### クラスター数が極端に少ない場合のfwildbootstrap

boottestのデフォルトtype=rademacherでは、取りうる値の数が少ないことが警告として出される

```{r warning=TRUE}
# 前段の結果を一旦消去
rm(list = c("data_extremely_small_cluster", "boot_lm"))

# seedを再設定
set.seed(1)
dqrng::dqset.seed(1)

data_extremely_small_cluster <- 
  return_dgp_cluster(
    N = N,
    N_C = N_C
  )

lm_fit <- 
  lm(Y ~ X, data = data_extremely_small_cluster)

boot_lm <- 
  fwildclusterboot::boottest(
    object = lm_fit,
    clustid = "C",
    param = "X",
    B = N_B
  )
```

```{r}
summary(boot_lm)$statistic
```

# 多重検定: FWER制御

参照：[因果推論の計量経済学（川口、澤田）：第3章　推測・検定の諸問題](https://github.com/keisemi/EconometriciansGuide_CausalInference/blob/main/main/inference_fwer.html)

## データの生成

### 定数の設定

```{r}
N <- 300       #標本サイズ
M <- 30  　　　#帰無仮説の数
M_F <- 10　　　#誤った帰無仮説の数
L <- 100　　　 #シミュレーション回数
alpha <- 0.05　#検出のサイズ
```

### すべての帰無仮説が真であるデータの生成

```{r}
z_allnull <- 
  (runif(N) >= 0.5)

df_list_allnull <- 
  seq_len(M) %>%
  purrr::map(
     ~ tibble::tibble(
       z = z_allnull,
       y = rnorm(N)
     )
  )
```

統計量の計算

```{r}
result_list_allnull <- 
  df_list_allnull %>%
  purrr::map(
    ~ lm(formula = y ~ z, data = .)
  )

# t統計量の取得
t_list_allnull <- 
  result_list_allnull %>%
  purrr::map(
    ~ summary(.) %>%
      coef() %>%
      .["zTRUE", "t value"]
  ) %>%
  purrr::reduce(c) 

# p統計量の取得
p_list_allnull <- 
  result_list_allnull %>% 
  purrr::map(
    ~ summary(.) %>% 
      coef() %>% 
      .["zTRUE", "Pr(>|t|)"]
  ) %>% 
  purrr::reduce(c)
```

各検定統計量の値を小さいものから大きいものに並べて、その値と0.05水準の臨界値をプロット

```{r}
ggplot(
  mapping = aes(
    x = seq_along(t_list_allnull),
    y = t_list_allnull %>% abs() %>% sort())) +
  geom_point() +
  geom_hline(yintercept = abs(qt(1 - alpha/2, df = N - 2)),
             lty = "dashed") +
  labs(x = "検定統計量の順位",
       y = "検定統計量の絶対値") +
  theme_classic()
```

```{r}
ggplot(
  mapping = aes(
    x = seq_along(p_list_allnull),
    y = p_list_allnull %>% abs() %>% sort())) +
  geom_point() +
  geom_hline(yintercept = alpha,
             lty = "dashed") +
  labs(x = "検定統計量の順位",
       y = "検定統計量の絶対値") +
  theme_classic()
```

t検定のうち、0.05水準で帰無仮説を棄却しているもの。

検定を繰り返すことによる偽棄却が発生している。

```{r}
t_reject_allnull <- 
  t_list_allnull %>% 
  abs() %>% 
  .[. > abs(qt(1 - alpha/2, df = N - 2))]

t_reject_allnull
```

### 偽である帰無仮説を含むデザイン

```{r}
z_somealt <- 
  (runif(N) >= 0.5)

df_list_null_somealt <- 
  seq_len(M - M_F) %>% 
  purrr::map(
    ~ tibble::tibble(
      z = z_somealt,
      y = rnorm(N)
    )
  )

df_list_alternative_somealt <- 
  seq_len(M_F - 2) %>% 
  purrr::map(
    ~ tibble::tibble(
      z = z_somealt,
      y = rnorm(N) + 0.3 * z_somealt
    )
  )

# 2つの帰無仮説について、係数を変えて統合
df_list_alternative_somealt <- c(
  df_list_alternative_somealt,
  seq(M_F - 1, M_F) %>% 
    purrr::map(
      ~ tibble::tibble(
        z = z_somealt,
        y = rnorm(N) + 0.5 * z_somealt
        )
      )
  )

result_list_null_somealt <- 
  df_list_null_somealt %>% 
  purrr::map(
    ~ lm(formula = y ~ z, data = .)
  )

result_list_alternative_somealt <- 
  df_list_alternative_somealt %>% 
  purrr::map(
    ~ lm(formula = y ~ z, data = .)
  )
```

## 分析と推計

### 全ての帰無仮説が真である場合

**A: Bonferroni補正**

有意水準を0.05/30 = 0.0016667に下げ、第一種の過誤を制御。

```{r}
ggplot(
  mapping = aes(x = seq_along(result_list_allnull),
                y = p_list_allnull %>% sort())
  ) +
  geom_point() +
  geom_hline(yintercept = alpha / M,
             lty = "dashed") +
  labs(x = "検定統計量の順位",
       y = "p値") +
  theme_classic()
```

```{r}
p_rejected_allnull_bonferroni <- 
  p_list_allnull %>% 
  .[. < alpha / M]

p_rejected_allnull_bonferroni
```

p.adjust関数を使った算出

```{r}
p_adjusted_allnull_bonferroni <- 
  p.adjust(
    p = p_list_allnull,
    method = "bonferroni"
  )

p_adjusted_allnull_bonferroni
```

**検定統計量の棄却域の補正による方法**

```{r}
ggplot(
  mapping = aes(x = seq_along(t_list_allnull),
                y = t_list_allnull %>% abs() %>% sort())
  ) +
  geom_point() +
  geom_hline(
    yintercept = abs(qt(1 - alpha/(2 * M), df = N - 2)),
    lty = "dashed") +
  labs(x = "検定統計量の順位",
       y = "検定統計量の絶対値") +
  theme_classic()
```

```{r}
t_rejected_allull_bonferroni_direct <- 
  t_list_allnull %>% 
  abs() %>% 
  .[. >= abs(qt(1 - alpha / (2 * M), df = N - 2))]

t_rejected_allull_bonferroni_direct
```

**シミュレーションによるFWERの評価**

100回のシミュレーション実施

```{r}
t_list_allnull_all <- 
  seq_len(L) %>% 
  purrr::map(
    ~ compute_t_statistics_null_effect(
      N = N,
      M = M,
      alpha = alpha,
      seed = .
    )
  )
```

補正を行わない場合

```{r}
t_rejected_allnull_all <- 
  t_list_allnull_all %>% 
  purrr::map(
    function(t_list_allnull) {
      length_rejected <- 
        t_list_allnull %>% 
        abs() %>% 
        .[. > abs(qt(1 - alpha / 2, df = N - 2))] %>% 
        length()
      return(length_rejected > 0)
    }
  ) %>% 
  purrr::reduce(c)

fwer_allnull <- 
  sum(t_rejected_allnull_all) / 
  length(t_rejected_allnull_all)

fwer_allnull
```

Bonferroni補正によるFWER制御

```{r}
t_rejected_allnull_bonferroni_all <- 
  t_list_allnull_all %>% 
  purrr::map(
    function(t_list_allnull) {
      length_rejected <- 
        t_list_allnull %>% 
        abs() %>% 
        .[. > abs(qt(1 - alpha / (2 * M), df = N - 2))] %>% 
        length()
      return(length_rejected > 0)
    }
  ) %>% 
  purrr::reduce(c)

fewr_allnull_bonferroni <- 
  sum(t_rejected_allnull_bonferroni_all) /
  length(t_rejected_allnull_bonferroni_all)

fewr_allnull_bonferroni
```

### 偽である帰無仮説を含む場合

```{r}
t_list_somealt_null <- 
  result_list_null_somealt %>% 
  purrr::map(
    ~ summary(.) %>% 
      coef() %>% 
      .["zTRUE", "t value"]
  ) %>% 
  purrr::reduce(c)

t_list_somealt_alternative <- 
  result_list_alternative_somealt %>% 
  purrr::map(
    ~ summary(.) %>% 
      coef() %>% 
      .["zTRUE", "t value"]
  ) %>% 
  purrr::reduce(c)

t_list_somealt <- c(
  t_list_somealt_null,
  t_list_somealt_alternative
)

null_list_somealt <- c(
  rep("null", 
      length = length(t_list_somealt_null)),
  rep("alternative", 
      length = length(t_list_somealt_alternative))
)

```

```{r}
p_list_somealt_null <- 
  result_list_null_somealt %>% 
  purrr::map(
    ~ summary(.) %>% 
      coef() %>% 
      .["zTRUE", "Pr(>|t|)"]
  ) %>% 
  purrr::reduce(c)

p_list_somealt_alternative <- 
  result_list_alternative_somealt %>% 
  purrr::map(
    ~ summary(.) %>% 
      coef() %>% 
      .["zTRUE", "Pr(>|t|)"]
  ) %>% 
  purrr::reduce(c)

p_list_somealt <- c(
 p_list_somealt_null,
 p_list_somealt_alternative
)
```

```{r}
ggplot(
  mapping = aes(
    x = seq_along(t_list_somealt),
    y = t_list_somealt[t_list_somealt 
                       %>% abs() %>% order()] %>% abs(),
    color = null_list_somealt[t_list_somealt 
                              %>% abs() %>% order()]
    )
  ) +
  geom_point() +
  geom_hline(yintercept = abs(qt(1 - alpha / 2, df = N - 2)),
             lty = "dashed") +
  scale_color_viridis_d() +
  labs(x = "検定統計量の順位",
       y = "検定統計量の絶対値",
       color = "帰無仮説であるか否か") +
  theme_classic()
```

```{r}
ggplot(
  mapping = aes(
    x = seq_along(p_list_somealt),
    y = p_list_somealt[p_list_somealt %>% order()],
    color = null_list_somealt[p_list_somealt %>% order()]
    )
  ) +
  geom_point() +
  geom_hline(yintercept = alpha,
             lty = "dashed") +
  scale_color_viridis_d() +
  labs(x = "検定統計量の順位",
       y = "p値",
       color = "帰無仮説であるか否か") +
  theme_classic()
```

p値のうち、0.05水準で正しく棄却しているもの

```{r}
p_rejected_somealt <- 
  p_list_somealt_alternative %>% 
  abs() %>% 
  .[. < alpha]

p_rejected_somealt
```

本来真の帰無仮説を誤って棄却しているもの

```{r}
p_rejected_somealt_false <- 
  p_list_somealt_null %>% 
  abs() %>% 
  .[. < alpha]

p_rejected_somealt_false
```

Bonferroni補正をかけた棄却域

```{r}
ggplot(
  mapping = aes(
    x = seq_along(t_list_somealt),
    y = t_list_somealt[t_list_somealt 
                       %>% abs() %>% order()] %>% abs(),
    color = null_list_somealt[t_list_somealt 
                              %>% abs() %>% order()]
    )
  ) +
  geom_point() +
  geom_hline(yintercept = abs(qt(1 - alpha / (2 * M),
                                 df = N - 2)),
             lty = "dashed") +
  scale_color_viridis_d() +
  labs(x = "検定統計量の順位",
       y = "検定統計量の絶対値",
       color = "帰無仮説であるか否か") +
  theme_classic()

```

Bonferroni補正した検定で正しく棄却しているもの

```{r}
t_rejected_sumealt_bonferroni <- 
  t_list_somealt_alternative %>% 
  abs() %>% 
  .[. > qt(1 - alpha / (2 * M), df = N - 2)]

t_rejected_sumealt_bonferroni
```

p値での結果

```{r}
ggplot(
  mapping = aes(
    x = seq_along(p_list_somealt),
    y = p_list_somealt[p_list_somealt %>% order()],
    color = null_list_somealt[p_list_somealt %>% order()]
    )
  ) +
  geom_point() +
  geom_hline(yintercept = alpha / M,
             lty = "dashed") +
  scale_color_viridis_d() +
  labs(x = "検定統計量の順位",
       y = "p値",
       color = "帰無仮説であるか否か") +
  theme_classic()
```

Bonferroni補正した検定で、0.0016667水準で正しく棄却しているもの

```{r}
p_rejected_somealt_bonferonni <- 
  p_list_somealt_alternative %>% 
  abs() %>% sort() %>% 
  .[. < alpha / M]

p_rejected_somealt_bonferonni
```

本来真の帰無仮説を誤って棄却しているもの（無し）

```{r}
p_rejected_somealt_false_bonferroni <- 
  p_list_somealt_null %>% 
  abs() %>% sort() %>% 
  .[. < alpha / M]

p_rejected_somealt_false_bonferroni
```

**FWERのシミュレーションによる計算**

100回のシミュレーションによりFWERを評価

```{r}
t_list_somealt_null <- 
  seq_len(L) %>% 
  purrr::map(
    ~ compute_t_statistics_null_effect(
      N = N,
      M = M - M_F,
      alpha = alpha,
      seed = .
    )
  )

t_list_somealt_alternative <- 
  seq_len(L) %>% 
  purrr::map(
    ~ compute_t_statistics_alternative_effect(
      N = N,
      M = M_F,
      alpha = alpha,
      seed = .
    )
  )
```

少なくとも1つの帰無仮説を誤って棄却したものの割合

1.補正なし

```{r}
t_rejected_somealt_null <- 
  t_list_somealt_null %>% 
  purrr::map(
    function(t_list_somealt) {
      length_rejected <- 
        t_list_somealt %>% 
        abs() %>% 
        .[. > abs(qt(1 - alpha / 2, df = N - 2))] %>% 
        length()
      return(length_rejected > 0)
    }
  ) %>% 
  purrr::reduce(c)

fwer_somealt <- 
  sum(t_rejected_somealt_null) /
  length(t_rejected_somealt_null)

fwer_somealt
```

2.Bonferroni補正あり

```{r}
t_rejected_somealt_bonferroni_null <- 
  t_list_somealt_null %>% 
  purrr::map(
    function(t_list_somealt) {
      length_rejected <- 
        t_list_somealt %>% 
        abs() %>% 
        .[. > abs(qt(1 - alpha / (2 * M), df = N - 2))] %>% 
        length()
      return(length_rejected > 0)
    }
  ) %>% 
  purrr::reduce(c)

fwer_somealt_bonferroni <- 
  sum(t_rejected_somealt_bonferroni_null) /
  length(t_rejected_somealt_bonferroni_null)

fwer_somealt_bonferroni
```

**シミュレーションによる検出力の計算**

100回のシミュレーションにおいて、正しい対立仮説を採用できた割合

1.補正なし

```{r}
t_rejected_somealt_alternative <- 
  t_list_somealt_alternative %>% 
  purrr::map(
    function(t_list_somealt) {
      length_rejected <- 
        t_list_somealt %>% 
        abs() %>% 
        .[. > abs(qt(1 - alpha / 2, df = N - 2))] %>% 
        length()
      return(length_rejected)
    }
  ) %>% 
  purrr::reduce(c)

power_somealt <- 
  sum(t_rejected_somealt_alternative) /
  (length(t_list_somealt_alternative) *
     length(t_list_somealt_alternative[[1]]))

power_somealt
```

2.  Bonferroni補正あり

FEWRを適正に保つことと引き換えに、検出力が低下している

```{r}
t_rejected_somealt_bonferroni_alternative <- 
  t_list_somealt_alternative %>% 
  purrr::map(
    function(t_list_somealt) {
      length_rejected <- 
        t_list_somealt %>% 
        abs() %>% 
        .[. > abs(qt(1 - alpha / (2 * M), df = N - 2))] %>% 
        length()
      return(length_rejected)
    }
  ) %>% 
  purrr::reduce(c)

power_somealt_bonferroni <- 
  sum(t_rejected_somealt_bonferroni_alternative) /
  (length(t_list_somealt_alternative) *
     length(t_list_somealt_alternative[[1]]))

power_somealt_bonferroni
```

### Bonferroni-Holm補正

**p値の有意水準の補正**

```{r}
ggplot(
  mapping = 
    aes(x = seq_along(p_list_somealt),
        y = p_list_somealt[p_list_somealt %>% order()],
        color = null_list_somealt[p_list_somealt %>% order()])
) +
  geom_point() +
  geom_hline(yintercept = alpha,
             lty = "dashed") +
  geom_line(
    mapping = 
      aes(x = seq_along(p_list_somealt),
          y = alpha / (M - seq_along(p_list_somealt) + 1)),
    color = "blue", lty = "dashed"
  ) +
  scale_color_viridis_d() +
  labs(x = "検定統計量の順位",
       y = "p値",
       color = "帰無仮説であるか否か") +
  theme_classic()
```

補正した水準で正しく棄却しているもの

（Bonferroni補正では棄却できなかった帰無仮説が、新たに1つ棄却出来ている）

```{r}
p_rejected_somealt_bonferonni_holm <- 
  p_list_somealt_alternative %>% 
  abs() %>% sort()

index <- (
  p_rejected_somealt_bonferonni_holm <=
    alpha / 
    (M - seq_along(p_rejected_somealt_bonferonni_holm) + 1)
  )

index <- 
  index %>% 
  cummin() %>% 
  as.logical()

p_rejected_somealt_bonferonni_holm <- 
  p_rejected_somealt_bonferonni_holm[index]

p_rejected_somealt_bonferonni_holm
```

```{r}
p_rejected_somealt_bonferonni
```

本来真の帰無仮説を誤って棄却しているもの

（誤って棄却しているものは無し）

```{r}
p_rejected_somealt_false_bonferonni_holm <- 
  p_list_somealt_null %>% 
  abs() %>% sort()

index <- (
  p_rejected_somealt_false_bonferroni <=
    alpha / 
    (M - seq_along(p_rejected_somealt_false_bonferonni_holm) + 1)
)

index <- 
  index %>% 
  cummin() %>% 
  as.logical()

p_rejected_somealt_false_bonferonni_holm <- 
  p_rejected_somealt_false_bonferonni_holm[index]

p_rejected_somealt_false_bonferonni_holm
```

p.ajust関数を使った方法

```{r}
p_adjusted_somealt_bonferroni_holm <- 
 p.adjust(
   p = p_list_somealt,
   method = "holm"
 ) 

p_adjusted_somealt_bonferroni_holm
```

**t値での検定**

（t値の棄却水準は、検定数が増えるに従って低下していくはずであり、参照サイトの表現は誤っていると思われる）

```{r}
ggplot(
  mapping = 
    aes(x = seq_along(t_list_somealt),
        y = t_list_somealt[t_list_somealt %>% abs() %>% order()] %>% abs(),
        color = null_list_somealt[t_list_somealt %>% abs() %>% order()]
        )
  ) +
  geom_point() +
  geom_hline(yintercept = abs(qt(1 - alpha / 2, df = N - 2)),
             lty = "dashed") +
  geom_line(
    mapping = 
      aes(x = seq_along(t_list_somealt),
          y = abs(qt(
            1 - alpha / (2 * (M - seq_along(t_list_somealt) + 1)),
            df = N - 2
          ))),
    color = "blue", lty = "dashed"
  ) +
  scale_color_viridis_d() +
  labs(x = "検定統計量の順位",
       y = "検定統計量の絶対値",
       color = "帰無仮説であるか否か") +
  theme_classic()
```

**Bonferroni-Holm補正によるFWERと検出力**

FWERは5%以下に抑えることが出来ている。

```{r}
t_rejected_somealt_bonferroni_holm_null <- 
  t_list_somealt_null %>% 
  purrr::map(
    function(t_list_somealt) {
      length_rejected <- 
        t_list_somealt %>% 
        abs() %>% sort(decreasing = TRUE) %>% 
        .[. >= abs(qt(
          1 - alpha / (2 * (M - seq_along(t_list_somealt))),
          df = N - 2
        ))] %>% 
        length()
      return(length_rejected > 0)
    }
  ) %>% 
  purrr::reduce(c)

fwer_somealt_bonferroni_holm <- 
  sum(t_rejected_somealt_bonferroni_holm_null) /
  length(t_rejected_somealt_bonferroni_holm_null)

fwer_somealt_bonferroni_holm
```

検出力は、Bonferroni補正に比べて若干改善している。

```{r}
t_rejected_somealt_bonferonni_holm_alternative <- 
  t_list_somealt_alternative %>% 
  purrr::map(
    function(t_list_somealt) {
      length_regected <- 
        t_list_somealt %>% 
        .[. >= abs(qt(
          1 - alpha / (2 * (M - seq_along(t_list_somealt) + 1)),
          df = N - 2
        ))] %>% 
        length()
      return(length_regected)
    }
  ) %>% 
  purrr::reduce(c)

power_somealt_bonferroni_holm <- 
  sum(t_rejected_somealt_bonferonni_holm_alternative) / 
  (length(t_list_somealt_alternative[[1]]) *
     length(t_list_somealt_alternative))

power_somealt_bonferroni_holm
```

# 多重検定：FDR制御

参照：[因果推論の計量経済学（川口、澤田）：第3章　推測・検定の諸問題](https://github.com/keisemi/EconometriciansGuide_CausalInference/blob/main/main/inference_fdr.html)

## データの生成

### 定数の設定とデータの生成

```{r}
set.seed(1)
N <- 500        #標本サイズ
M <- 60         #帰無仮説の数
M_0 <- 45　　　 #正しい帰無仮説の数
L <- 100        #シミュレーション回数
alpha <- 0.05　 #有意水準
tau_population <- 0.2
```

```{r}
z <- (runif(N) >= 0.5)

df_list_1 <-
  seq_len(M - M_0) %>% 
  purrr::map(
    ~ tibble::tibble(
      z = z,
      y = rnorm(N) + tau_population * z
    )
  )
  
df_list_0 <- 
  seq_len(M_0) %>% 
  purrr::map(
    ~ tibble::tibble(
      z = z,
      y = rnorm(N)
    )
  )

df_list <- 
  c(df_list_1, df_list_0)
```

###検定統計量の計算 60個の独立な線形回帰を行い、t値とp値を計算する

```{r}
result_list_1 <- 
  df_list_1 %>% 
  purrr::map(
    ~ lm(y ~ z, data = .)
  )

result_list_0 <- 
  df_list_0 %>% 
  purrr::map(
    ~ lm(y ~ z, data = .)
  )
```

```{r}
t_list_1 <- 
  result_list_1 %>% 
  purrr::map(
    ~ summary(.) %>% 
      coef() %>% 
      .["zTRUE", "t value"]
  ) %>% 
  purrr::reduce(c)

t_list_0 <- 
  result_list_0 %>% 
  purrr::map(
    ~ summary(.) %>% 
      coef() %>% 
      .["zTRUE", "t value"]
  ) %>% 
  purrr::reduce(c)
```

```{r}
p_list_1 <- 
  result_list_1 %>% 
  purrr::map(
    ~ summary(.) %>% 
      coef() %>% 
      .["zTRUE", "Pr(>|t|)"]
  ) %>% 
  purrr::reduce(c)

p_list_0 <- 
  result_list_0 %>% 
  purrr::map(
    ~ summary(.) %>% 
      coef() %>% 
      .["zTRUE", "Pr(>|t|)"]
  ) %>% 
  purrr::reduce(c)
```

## 分析と推計

### FDRの計算

帰無仮説が偽である15個の検定統計量の絶対値を小さいものから順にプロット

```{r}
ggplot(
  mapping = 
    aes(x = seq_along(t_list_1),
        y = t_list_1 %>% abs() %>% sort()
        )
  ) +
  geom_point() +
  geom_hline(yintercept = abs(qnorm(1 - alpha / 2)),
             lty = "dashed") +
  labs(x = "検定統計量の順位",
       y = "検定統計量の絶対値") +
  theme_classic()
```

```{r}
ggplot(
  mapping = 
    aes(x = seq_along(p_list_1),
        y = p_list_1 %>% sort()
        )
  ) +
  geom_point() +
  geom_hline(yintercept = alpha,
             lty = "dashed") +
  labs(x = "検定統計量の順位",
       y = "検定統計量の絶対値") +
  theme_classic()
```

```{r}
ggplot(
  mapping = 
    aes(x = seq_along(t_list_0),
        y = t_list_0 %>% abs() %>% sort())
) +
  geom_point() +
  geom_hline(yintercept = abs(qnorm(1 - alpha / 2)),
             lty = "dashed") +
  labs(x = "検定統計量の順位",
       y = "p値") +
  theme_classic()
```

```{r}
ggplot(
  mapping = 
    aes(x = seq_along(p_list_0),
        y = p_list_0 %>% sort())
) +
  geom_point() +
  geom_hline(yintercept = alpha,
             lty = "dashed") +
  labs(x = "検定統計量の順位",
       y = "p値") +
  theme_classic()
```

偽である15個の帰無仮説のうち、正しく棄却された検定統計量

```{r}
t_list_rejected_1 <- 
  t_list_1 [
    abs(t_list_1) > abs(qnorm(1 - alpha / 2))
    ]

t_list_rejected_1
```

偽である45個の帰無仮説のうち、誤って棄却された検定統計量

```{r}
t_list_rejected_0 <- 
  t_list_0[
    abs(t_list_0) > abs(qnorm(1 - alpha / 2))
  ]

t_list_rejected_0
```

FDRは棄却された帰無仮説のうち、誤って棄却された帰無仮説の割合

```{r}
fdr <- 
  length(t_list_rejected_0) /
  (length(t_list_rejected_0) + length(t_list_rejected_1))

fdr
```

### FDR補正

**Benjamini-Hochberg補正**

```{r}
p_list_sorted <- 
  c(p_list_1, p_list_0) %>% 
  sort()

i <- M
flag_continue <- TRUE

while(flag_continue & i > 1) {
  test <- p_list_sorted[i] <= (i / M) * alpha
  if(test) {
    flag_continue <- FALSE
  }
  i <- i - 1  #改行がないと正しく機能しない
}
```

これにより棄却された帰無仮説の数とそのp値の閾値

```{r}
i
```

```{r}
p_list_sorted[i]
```

正しく棄却された帰無仮説のp値

```{r}
p_list_rejected_benjamini_hotchberg_1 <- 
  p_list_1[p_list_1 <= p_list_sorted[i]]

p_list_rejected_benjamini_hotchberg_1
```

誤って棄却された帰無仮説のp値

```{r}
p_list_rejected_benjamini_hotchberg_0 <- 
  p_list_0[p_list_0 <= p_list_sorted[i]]

p_list_rejected_benjamini_hotchberg_0
```

Benjamini-Hochberg法によるFDR

```{r}
fdr_benjamini_hotchberg <- 
  length(p_list_rejected_benjamini_hotchberg_0) /
  sum(length(p_list_rejected_benjamini_hotchberg_1),
      length(p_list_rejected_benjamini_hotchberg_0))

fdr_benjamini_hotchberg
```

100回のシミュレーションによるFDRの期待値の計算

```{r}
p_list_all <- 
  seq_len(L) %>% 
  purrr::map(
    ~ compute_p_value_mixed_effect(
      N = N,
      M = M,
      M_0 = M_0,
      seed = .
    )
  )
```

```{r}
p_value_all <- 
  p_list_all %>% 
  purrr::map(
    ~ compute_p_value_benjamini_hotchberg(
      p_list_1 = .$p_list_1,
      p_list_0 = .$p_list_0,
      alpha = alpha
    )
  )
```

```{r}
fdr_expected <- 
  purrr::map2(
    p_list_all,
    p_value_all,
    ~ compute_fdr(
      p_list_1 = .x$p_list_1,
      p_list_0 = .x$p_list_0,
      p_value = .y
    )
  ) %>% 
  purrr::reduce(c) %>% 
  mean()

fdr_expected
```

期待FDRが `r fdr_expected` となり、0.05よりも小さい値に制御されている。

**Benjamini-Yekutieli補正**

検定間の任意の相関においてFDR制御可能だが、検出力が劣る

```{r}
p_list_sorted <- 
  c(p_list_1, p_list_0) %>% 
  sort()

i <- M
flag_continue <- TRUE

while(flag_continue & i > 1) {
  test <- (p_list_sorted[i] <= 
    (i / M) * alpha / sum(1 / seq_len(M)))
  if(test) {
    flag_continue <- FALSE
    }
  i <- i - 1
}
```

これによる棄却された帰無仮説の数

```{r}
i
```

そのp値の閾値

```{r}
p_list_sorted[i]
```

正しく棄却された帰無仮説のp値

```{r}
p_list_rejected_benjamini_yekutieli_1 <- 
  p_list_1[p_list_1 <= p_list_sorted[i]]

p_list_rejected_benjamini_yekutieli_1
```

誤って棄却された帰無仮説のp値

```{r}
p_list_rejected_benjamini_yekutieli_0 <- 
  p_list_0[p_list_0 <= p_list_sorted[i]]

p_list_rejected_benjamini_yekutieli_0
```

Benjamini-Yekutieli補正によるFDR

```{r}
fdr_benjamini_yekutieli <- 
  length(p_list_rejected_benjamini_yekutieli_0) /
  sum(length(p_list_rejected_benjamini_yekutieli_0),
      length(p_list_rejected_benjamini_yekutieli_1))

fdr_benjamini_yekutieli
```

100回のシミュレーションによる期待FDRの計算

```{r}
p_value_all <- 
  p_list_all %>% 
  purrr::map(
    ~ compute_p_value_benjamini_yekutieli(
      p_list_1 = .$p_list_1,
      p_list_0 = .$p_list_0,
      alpha = alpha
    )
  )

fdr_expected <- 
  purrr::map2(
    p_list_all,
    p_value_all,
    ~ compute_fdr(
      p_list_1 = .x$p_list_1,
      p_list_0 = .x$p_list_0,
      p_value = .y
    )
  ) %>% 
  purrr::reduce(c) %>% 
  mean()

fdr_expected
```
